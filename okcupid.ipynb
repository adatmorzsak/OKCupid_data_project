{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original dataset is from here:\n",
    "https://www.kaggle.com/datasets/andrewmvd/okcupid-profiles?resource=download&select=okcupid_profiles.csv\n",
    "\n",
    "I used a Virtual Machine to this analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the csv file into a dataframe\n",
    "df=pd.read_csv('/home/ubuntu/host/okcupid_profiles.csv', delimiter= ',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59946, 31)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking the number of all rows and columns\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 59946 entries, 0 to 59945\n",
      "Data columns (total 31 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   age          59946 non-null  int64  \n",
      " 1   status       59946 non-null  object \n",
      " 2   sex          59946 non-null  object \n",
      " 3   orientation  59946 non-null  object \n",
      " 4   body_type    54650 non-null  object \n",
      " 5   diet         35551 non-null  object \n",
      " 6   drinks       56961 non-null  object \n",
      " 7   drugs        45866 non-null  object \n",
      " 8   education    53318 non-null  object \n",
      " 9   ethnicity    54266 non-null  object \n",
      " 10  height       59943 non-null  float64\n",
      " 11  income       59946 non-null  int64  \n",
      " 12  job          51748 non-null  object \n",
      " 13  last_online  59946 non-null  object \n",
      " 14  location     59946 non-null  object \n",
      " 15  offspring    24385 non-null  object \n",
      " 16  pets         40025 non-null  object \n",
      " 17  religion     39720 non-null  object \n",
      " 18  sign         48890 non-null  object \n",
      " 19  smokes       54434 non-null  object \n",
      " 20  speaks       59896 non-null  object \n",
      " 21  essay0       54458 non-null  object \n",
      " 22  essay1       52374 non-null  object \n",
      " 23  essay2       50308 non-null  object \n",
      " 24  essay3       48470 non-null  object \n",
      " 25  essay4       49409 non-null  object \n",
      " 26  essay5       49096 non-null  object \n",
      " 27  essay6       46175 non-null  object \n",
      " 28  essay7       47495 non-null  object \n",
      " 29  essay8       40721 non-null  object \n",
      " 30  essay9       47343 non-null  object \n",
      "dtypes: float64(1), int64(2), object(28)\n",
      "memory usage: 14.2+ MB\n"
     ]
    }
   ],
   "source": [
    "#checking if there are missing values and the data types\n",
    "#-->we have missing values that we have to fill & 'height' needs to convert to int\n",
    "#-->\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>status</th>\n",
       "      <th>sex</th>\n",
       "      <th>orientation</th>\n",
       "      <th>body_type</th>\n",
       "      <th>diet</th>\n",
       "      <th>drinks</th>\n",
       "      <th>drugs</th>\n",
       "      <th>education</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>...</th>\n",
       "      <th>essay0</th>\n",
       "      <th>essay1</th>\n",
       "      <th>essay2</th>\n",
       "      <th>essay3</th>\n",
       "      <th>essay4</th>\n",
       "      <th>essay5</th>\n",
       "      <th>essay6</th>\n",
       "      <th>essay7</th>\n",
       "      <th>essay8</th>\n",
       "      <th>essay9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>single</td>\n",
       "      <td>m</td>\n",
       "      <td>straight</td>\n",
       "      <td>a little extra</td>\n",
       "      <td>strictly anything</td>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>working on college/university</td>\n",
       "      <td>asian, white</td>\n",
       "      <td>...</td>\n",
       "      <td>about me:  i would love to think that i was so...</td>\n",
       "      <td>currently working as an international agent fo...</td>\n",
       "      <td>making people laugh. ranting about a good salt...</td>\n",
       "      <td>the way i look. i am a six foot half asian, ha...</td>\n",
       "      <td>books: absurdistan, the republic, of mice and ...</td>\n",
       "      <td>food. water. cell phone. shelter.</td>\n",
       "      <td>duality and humorous things</td>\n",
       "      <td>trying to find someone to hang out with. i am ...</td>\n",
       "      <td>i am new to california and looking for someone...</td>\n",
       "      <td>you want to be swept off your feet! you are ti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35</td>\n",
       "      <td>single</td>\n",
       "      <td>m</td>\n",
       "      <td>straight</td>\n",
       "      <td>average</td>\n",
       "      <td>mostly other</td>\n",
       "      <td>often</td>\n",
       "      <td>sometimes</td>\n",
       "      <td>working on space camp</td>\n",
       "      <td>white</td>\n",
       "      <td>...</td>\n",
       "      <td>i am a chef: this is what that means. 1. i am ...</td>\n",
       "      <td>dedicating everyday to being an unbelievable b...</td>\n",
       "      <td>being silly. having ridiculous amonts of fun w...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>i am die hard christopher moore fan. i don't r...</td>\n",
       "      <td>delicious porkness in all of its glories. my b...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>i am very open and will share just about anyth...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>available</td>\n",
       "      <td>m</td>\n",
       "      <td>straight</td>\n",
       "      <td>thin</td>\n",
       "      <td>anything</td>\n",
       "      <td>socially</td>\n",
       "      <td>NaN</td>\n",
       "      <td>graduated from masters program</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>i'm not ashamed of much, but writing public te...</td>\n",
       "      <td>i make nerdy software for musicians, artists, ...</td>\n",
       "      <td>improvising in different contexts. alternating...</td>\n",
       "      <td>my large jaw and large glasses are the physica...</td>\n",
       "      <td>okay this is where the cultural matrix gets so...</td>\n",
       "      <td>movement conversation creation contemplation t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>viewing. listening. dancing. talking. drinking...</td>\n",
       "      <td>when i was five years old, i was known as \"the...</td>\n",
       "      <td>you are bright, open, intense, silly, ironic, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23</td>\n",
       "      <td>single</td>\n",
       "      <td>m</td>\n",
       "      <td>straight</td>\n",
       "      <td>thin</td>\n",
       "      <td>vegetarian</td>\n",
       "      <td>socially</td>\n",
       "      <td>NaN</td>\n",
       "      <td>working on college/university</td>\n",
       "      <td>white</td>\n",
       "      <td>...</td>\n",
       "      <td>i work in a library and go to school. . .</td>\n",
       "      <td>reading things written by old dead people</td>\n",
       "      <td>playing synthesizers and organizing books acco...</td>\n",
       "      <td>socially awkward but i do my best</td>\n",
       "      <td>bataille, celine, beckett. . . lynch, jarmusch...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cats and german philosophy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>you feel so inclined.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29</td>\n",
       "      <td>single</td>\n",
       "      <td>m</td>\n",
       "      <td>straight</td>\n",
       "      <td>athletic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>graduated from college/university</td>\n",
       "      <td>asian, black, other</td>\n",
       "      <td>...</td>\n",
       "      <td>hey how's it going? currently vague on the pro...</td>\n",
       "      <td>work work work work + play</td>\n",
       "      <td>creating imagery to look at: http://bagsbrown....</td>\n",
       "      <td>i smile a lot and my inquisitive nature</td>\n",
       "      <td>music: bands, rappers, musicians at the moment...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age     status sex orientation       body_type               diet  \\\n",
       "0   22     single   m    straight  a little extra  strictly anything   \n",
       "1   35     single   m    straight         average       mostly other   \n",
       "2   38  available   m    straight            thin           anything   \n",
       "3   23     single   m    straight            thin         vegetarian   \n",
       "4   29     single   m    straight        athletic                NaN   \n",
       "\n",
       "     drinks      drugs                          education  \\\n",
       "0  socially      never      working on college/university   \n",
       "1     often  sometimes              working on space camp   \n",
       "2  socially        NaN     graduated from masters program   \n",
       "3  socially        NaN      working on college/university   \n",
       "4  socially      never  graduated from college/university   \n",
       "\n",
       "             ethnicity  ...  \\\n",
       "0         asian, white  ...   \n",
       "1                white  ...   \n",
       "2                  NaN  ...   \n",
       "3                white  ...   \n",
       "4  asian, black, other  ...   \n",
       "\n",
       "                                              essay0  \\\n",
       "0  about me:  i would love to think that i was so...   \n",
       "1  i am a chef: this is what that means. 1. i am ...   \n",
       "2  i'm not ashamed of much, but writing public te...   \n",
       "3          i work in a library and go to school. . .   \n",
       "4  hey how's it going? currently vague on the pro...   \n",
       "\n",
       "                                              essay1  \\\n",
       "0  currently working as an international agent fo...   \n",
       "1  dedicating everyday to being an unbelievable b...   \n",
       "2  i make nerdy software for musicians, artists, ...   \n",
       "3          reading things written by old dead people   \n",
       "4                         work work work work + play   \n",
       "\n",
       "                                              essay2  \\\n",
       "0  making people laugh. ranting about a good salt...   \n",
       "1  being silly. having ridiculous amonts of fun w...   \n",
       "2  improvising in different contexts. alternating...   \n",
       "3  playing synthesizers and organizing books acco...   \n",
       "4  creating imagery to look at: http://bagsbrown....   \n",
       "\n",
       "                                              essay3  \\\n",
       "0  the way i look. i am a six foot half asian, ha...   \n",
       "1                                                NaN   \n",
       "2  my large jaw and large glasses are the physica...   \n",
       "3                  socially awkward but i do my best   \n",
       "4            i smile a lot and my inquisitive nature   \n",
       "\n",
       "                                              essay4  \\\n",
       "0  books: absurdistan, the republic, of mice and ...   \n",
       "1  i am die hard christopher moore fan. i don't r...   \n",
       "2  okay this is where the cultural matrix gets so...   \n",
       "3  bataille, celine, beckett. . . lynch, jarmusch...   \n",
       "4  music: bands, rappers, musicians at the moment...   \n",
       "\n",
       "                                              essay5  \\\n",
       "0                  food. water. cell phone. shelter.   \n",
       "1  delicious porkness in all of its glories. my b...   \n",
       "2  movement conversation creation contemplation t...   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "\n",
       "                        essay6  \\\n",
       "0  duality and humorous things   \n",
       "1                          NaN   \n",
       "2                          NaN   \n",
       "3   cats and german philosophy   \n",
       "4                          NaN   \n",
       "\n",
       "                                              essay7  \\\n",
       "0  trying to find someone to hang out with. i am ...   \n",
       "1                                                NaN   \n",
       "2  viewing. listening. dancing. talking. drinking...   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "\n",
       "                                              essay8  \\\n",
       "0  i am new to california and looking for someone...   \n",
       "1  i am very open and will share just about anyth...   \n",
       "2  when i was five years old, i was known as \"the...   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "\n",
       "                                              essay9  \n",
       "0  you want to be swept off your feet! you are ti...  \n",
       "1                                                NaN  \n",
       "2  you are bright, open, intense, silly, ironic, ...  \n",
       "3                              you feel so inclined.  \n",
       "4                                                NaN  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scanning the first 5 rows of the dataset\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 59946 entries, 0 to 59945\n",
      "Data columns (total 21 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   age          59946 non-null  int64  \n",
      " 1   status       59946 non-null  object \n",
      " 2   sex          59946 non-null  object \n",
      " 3   orientation  59946 non-null  object \n",
      " 4   body_type    54650 non-null  object \n",
      " 5   diet         35551 non-null  object \n",
      " 6   drinks       56961 non-null  object \n",
      " 7   drugs        45866 non-null  object \n",
      " 8   education    53318 non-null  object \n",
      " 9   ethnicity    54266 non-null  object \n",
      " 10  height       59943 non-null  float64\n",
      " 11  income       59946 non-null  int64  \n",
      " 12  job          51748 non-null  object \n",
      " 13  last_online  59946 non-null  object \n",
      " 14  location     59946 non-null  object \n",
      " 15  offspring    24385 non-null  object \n",
      " 16  pets         40025 non-null  object \n",
      " 17  religion     39720 non-null  object \n",
      " 18  sign         48890 non-null  object \n",
      " 19  smokes       54434 non-null  object \n",
      " 20  speaks       59896 non-null  object \n",
      "dtypes: float64(1), int64(2), object(18)\n",
      "memory usage: 9.6+ MB\n"
     ]
    }
   ],
   "source": [
    "#for the analysis we won't need the essay columns -->get rid of them\n",
    "df.drop(['essay0','essay1','essay2','essay3','essay4','essay5','essay6','essay7','essay8','essay9'], axis='columns', inplace=True)\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we have to fill the NULL values, based on the column's other values.\n",
    "For this, I checked the unique values in each relevant columns, then filled the NULL values with relevant data.\n",
    "The string-type columns I filled with the value 'unknown', the 'height' column filled with the average of height values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([75., 70., 68., 71., 66., 67., 65., 72., 62., 64., 69., 73., 74.,\n",
       "       60., 63., 76., 61., 78., 79., 59., 80., 91., 83., 77., 58., 56.,\n",
       "       95., 57., 87., 81., 36., 43., 52., 55., 53., 93.,  8., 54., 82.,\n",
       "        3., 86., 42., 84., 94., 50.,  6., 47., 49., 48., 90., 88., nan,\n",
       "       37.,  9., 51.,  1., 92., 26., 85., 89.,  4.])"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['height'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['height'] = df.height.fillna(df['height'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['a little extra', 'average', 'thin', 'athletic', 'fit', nan,\n",
       "       'skinny', 'curvy', 'full figured', 'jacked', 'rather not say',\n",
       "       'used up', 'overweight'], dtype=object)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['body_type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['strictly anything', 'mostly other', 'anything', 'vegetarian', nan,\n",
       "       'mostly anything', 'mostly vegetarian', 'strictly vegan',\n",
       "       'strictly vegetarian', 'mostly vegan', 'strictly other',\n",
       "       'mostly halal', 'other', 'vegan', 'mostly kosher',\n",
       "       'strictly halal', 'halal', 'strictly kosher', 'kosher'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['diet'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['socially', 'often', 'not at all', 'rarely', nan, 'very often',\n",
       "       'desperately'], dtype=object)"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['drinks'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['never', 'sometimes', nan, 'often'], dtype=object)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['drugs'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['working on college/university', 'working on space camp',\n",
       "       'graduated from masters program',\n",
       "       'graduated from college/university', 'working on two-year college',\n",
       "       nan, 'graduated from high school', 'working on masters program',\n",
       "       'graduated from space camp', 'college/university',\n",
       "       'dropped out of space camp', 'graduated from ph.d program',\n",
       "       'graduated from law school', 'working on ph.d program',\n",
       "       'two-year college', 'graduated from two-year college',\n",
       "       'working on med school', 'dropped out of college/university',\n",
       "       'space camp', 'graduated from med school',\n",
       "       'dropped out of high school', 'working on high school',\n",
       "       'masters program', 'dropped out of ph.d program',\n",
       "       'dropped out of two-year college', 'dropped out of med school',\n",
       "       'high school', 'working on law school', 'law school',\n",
       "       'dropped out of masters program', 'ph.d program',\n",
       "       'dropped out of law school', 'med school'], dtype=object)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['education'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['asian, white', 'white', nan, 'asian, black, other',\n",
       "       'white, other', 'hispanic / latin, white', 'hispanic / latin',\n",
       "       'pacific islander, white', 'asian', 'black, white',\n",
       "       'pacific islander', 'asian, native american',\n",
       "       'asian, pacific islander', 'black, native american, white',\n",
       "       'middle eastern, other', 'native american, white', 'indian',\n",
       "       'black', 'black, native american, hispanic / latin, other',\n",
       "       'black, native american, hispanic / latin',\n",
       "       'asian, black, pacific islander',\n",
       "       'asian, middle eastern, black, native american, indian, pacific islander, hispanic / latin, white, other',\n",
       "       'other', 'hispanic / latin, other', 'asian, black',\n",
       "       'middle eastern, white', 'native american, white, other',\n",
       "       'black, native american', 'black, white, other',\n",
       "       'hispanic / latin, white, other', 'middle eastern', 'black, other',\n",
       "       'native american, hispanic / latin, white', 'black, indian',\n",
       "       'indian, white, other', 'middle eastern, indian, other',\n",
       "       'black, native american, hispanic / latin, white, other',\n",
       "       'pacific islander, hispanic / latin',\n",
       "       'black, hispanic / latin, white', 'native american',\n",
       "       'indian, white', 'asian, white, other', 'black, hispanic / latin',\n",
       "       'asian, hispanic / latin, white',\n",
       "       'middle eastern, hispanic / latin',\n",
       "       'asian, black, native american, pacific islander, white',\n",
       "       'middle eastern, indian', 'asian, indian',\n",
       "       'pacific islander, other', 'black, native american, white, other',\n",
       "       'black, pacific islander',\n",
       "       'middle eastern, native american, white',\n",
       "       'asian, native american, white, other',\n",
       "       'pacific islander, hispanic / latin, white', 'indian, other',\n",
       "       'asian, pacific islander, other', 'black, hispanic / latin, other',\n",
       "       'asian, black, native american',\n",
       "       'black, native american, hispanic / latin, white',\n",
       "       'native american, hispanic / latin', 'indian, hispanic / latin',\n",
       "       'native american, pacific islander',\n",
       "       'asian, black, native american, hispanic / latin, white',\n",
       "       'asian, black, white',\n",
       "       'asian, black, native american, pacific islander, other',\n",
       "       'middle eastern, hispanic / latin, white',\n",
       "       'asian, pacific islander, white',\n",
       "       'asian, native american, hispanic / latin, white, other',\n",
       "       'asian, hispanic / latin', 'asian, pacific islander, white, other',\n",
       "       'middle eastern, white, other',\n",
       "       'asian, pacific islander, hispanic / latin',\n",
       "       'black, native american, indian, other',\n",
       "       'native american, hispanic / latin, white, other',\n",
       "       'black, native american, other', 'asian, other',\n",
       "       'middle eastern, hispanic / latin, other',\n",
       "       'pacific islander, hispanic / latin, white, other',\n",
       "       'asian, black, hispanic / latin',\n",
       "       'asian, pacific islander, hispanic / latin, white',\n",
       "       'asian, black, native american, white',\n",
       "       'asian, middle eastern, white, other',\n",
       "       'native american, pacific islander, hispanic / latin',\n",
       "       'asian, native american, white',\n",
       "       'native american, pacific islander, hispanic / latin, white, other',\n",
       "       'indian, pacific islander', 'asian, middle eastern, black',\n",
       "       'asian, middle eastern, indian', 'asian, middle eastern, white',\n",
       "       'pacific islander, white, other',\n",
       "       'black, pacific islander, hispanic / latin',\n",
       "       'asian, middle eastern', 'asian, hispanic / latin, other',\n",
       "       'middle eastern, black, native american, indian, white, other',\n",
       "       'middle eastern, pacific islander, other', 'middle eastern, black',\n",
       "       'asian, indian, pacific islander',\n",
       "       'black, native american, pacific islander',\n",
       "       'native american, indian',\n",
       "       'asian, middle eastern, black, native american, indian, pacific islander, hispanic / latin, white',\n",
       "       'black, indian, other',\n",
       "       'asian, middle eastern, indian, hispanic / latin, white, other',\n",
       "       'middle eastern, black, white',\n",
       "       'asian, hispanic / latin, white, other',\n",
       "       'native american, hispanic / latin, other',\n",
       "       'middle eastern, black, pacific islander, white',\n",
       "       'asian, black, native american, hispanic / latin',\n",
       "       'native american, other', 'black, indian, white',\n",
       "       'asian, native american, hispanic / latin, white',\n",
       "       'black, native american, indian, white',\n",
       "       'middle eastern, black, indian, pacific islander, hispanic / latin, white',\n",
       "       'middle eastern, hispanic / latin, white, other',\n",
       "       'asian, black, native american, other',\n",
       "       'native american, pacific islander, hispanic / latin, white',\n",
       "       'asian, indian, other',\n",
       "       'middle eastern, native american, hispanic / latin, white, other',\n",
       "       'asian, middle eastern, black, pacific islander, hispanic / latin, white',\n",
       "       'black, native american, pacific islander, hispanic / latin, white, other',\n",
       "       'asian, middle eastern, native american, hispanic / latin, white',\n",
       "       'asian, middle eastern, black, native american, pacific islander, hispanic / latin, white, other',\n",
       "       'asian, indian, white',\n",
       "       'native american, pacific islander, white, other',\n",
       "       'middle eastern, black, native american, indian, pacific islander, hispanic / latin, white',\n",
       "       'asian, middle eastern, other', 'middle eastern, pacific islander',\n",
       "       'asian, black, hispanic / latin, other',\n",
       "       'asian, middle eastern, black, native american, hispanic / latin, white',\n",
       "       'middle eastern, black, hispanic / latin',\n",
       "       'black, pacific islander, white',\n",
       "       'asian, middle eastern, black, native american, indian, pacific islander, hispanic / latin, other',\n",
       "       'middle eastern, black, native american, indian, hispanic / latin, white',\n",
       "       'asian, pacific islander, hispanic / latin, white, other',\n",
       "       'middle eastern, indian, white', 'asian, indian, white, other',\n",
       "       'middle eastern, black, native american, white, other',\n",
       "       'black, native american, pacific islander, other',\n",
       "       'middle eastern, black, native american, white',\n",
       "       'asian, indian, pacific islander, other',\n",
       "       'asian, black, native american, white, other',\n",
       "       'black, indian, hispanic / latin, white',\n",
       "       'asian, middle eastern, black, native american, indian, pacific islander, white',\n",
       "       'asian, black, pacific islander, hispanic / latin',\n",
       "       'middle eastern, black, native american, indian, pacific islander, hispanic / latin, white, other',\n",
       "       'asian, black, native american, indian',\n",
       "       'asian, black, indian, hispanic / latin, other',\n",
       "       'indian, hispanic / latin, other',\n",
       "       'asian, indian, hispanic / latin',\n",
       "       'asian, native american, pacific islander, white, other',\n",
       "       'asian, black, native american, indian, hispanic / latin, white, other',\n",
       "       'asian, indian, hispanic / latin, white',\n",
       "       'pacific islander, hispanic / latin, other',\n",
       "       'asian, indian, pacific islander, hispanic / latin, white, other',\n",
       "       'indian, hispanic / latin, white',\n",
       "       'asian, native american, pacific islander, hispanic / latin, white, other',\n",
       "       'asian, pacific islander, hispanic / latin, other',\n",
       "       'asian, black, hispanic / latin, white, other',\n",
       "       'black, indian, hispanic / latin',\n",
       "       'middle eastern, black, native american, hispanic / latin, white',\n",
       "       'black, pacific islander, other',\n",
       "       'black, native american, pacific islander, white',\n",
       "       'asian, black, native american, pacific islander',\n",
       "       'asian, indian, hispanic / latin, other',\n",
       "       'middle eastern, native american',\n",
       "       'middle eastern, native american, hispanic / latin',\n",
       "       'black, hispanic / latin, white, other',\n",
       "       'asian, native american, pacific islander, hispanic / latin, white',\n",
       "       'asian, native american, hispanic / latin',\n",
       "       'black, native american, indian, hispanic / latin, white, other',\n",
       "       'asian, middle eastern, hispanic / latin, white',\n",
       "       'black, native american, pacific islander, white, other',\n",
       "       'native american, indian, pacific islander, hispanic / latin',\n",
       "       'black, indian, white, other',\n",
       "       'asian, middle eastern, native american, pacific islander, hispanic / latin, white, other',\n",
       "       'native american, pacific islander, white',\n",
       "       'middle eastern, indian, white, other',\n",
       "       'asian, black, white, other',\n",
       "       'middle eastern, native american, hispanic / latin, white',\n",
       "       'indian, hispanic / latin, white, other',\n",
       "       'asian, middle eastern, black, pacific islander',\n",
       "       'asian, middle eastern, black, indian, pacific islander, hispanic / latin, white',\n",
       "       'asian, middle eastern, indian, other',\n",
       "       'asian, middle eastern, black, white, other',\n",
       "       'black, native american, pacific islander, hispanic / latin, white',\n",
       "       'black, native american, indian, pacific islander, hispanic / latin',\n",
       "       'asian, black, pacific islander, white',\n",
       "       'middle eastern, pacific islander, hispanic / latin',\n",
       "       'black, native american, indian, white, other',\n",
       "       'asian, black, hispanic / latin, white',\n",
       "       'asian, black, native american, indian, pacific islander, white',\n",
       "       'asian, black, native american, indian, pacific islander, hispanic / latin',\n",
       "       'asian, middle eastern, hispanic / latin, white, other',\n",
       "       'middle eastern, black, native american, indian',\n",
       "       'asian, native american, pacific islander',\n",
       "       'asian, black, native american, pacific islander, white, other',\n",
       "       'asian, middle eastern, hispanic / latin',\n",
       "       'asian, black, pacific islander, other',\n",
       "       'asian, native american, indian, pacific islander, hispanic / latin, white',\n",
       "       'middle eastern, native american, white, other',\n",
       "       'asian, native american, hispanic / latin, other',\n",
       "       'native american, indian, white',\n",
       "       'black, native american, pacific islander, hispanic / latin',\n",
       "       'asian, native american, pacific islander, white',\n",
       "       'black, native american, indian',\n",
       "       'indian, pacific islander, hispanic / latin, white',\n",
       "       'asian, middle eastern, black, native american, indian, pacific islander, hispanic / latin',\n",
       "       'asian, middle eastern, indian, hispanic / latin',\n",
       "       'asian, middle eastern, native american, pacific islander, other',\n",
       "       'black, native american, indian, pacific islander',\n",
       "       'asian, middle eastern, native american, pacific islander, white, other',\n",
       "       'asian, native american, other', 'middle eastern, black, other',\n",
       "       'asian, black, pacific islander, hispanic / latin, white',\n",
       "       'asian, middle eastern, native american, indian, pacific islander, hispanic / latin, white',\n",
       "       'asian, native american, indian, pacific islander, hispanic / latin, white, other',\n",
       "       'asian, middle eastern, black, pacific islander, hispanic / latin',\n",
       "       'asian, black, pacific islander, white, other',\n",
       "       'asian, black, indian'], dtype=object)"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['ethnicity'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['transportation', 'hospitality / travel', nan, 'student',\n",
       "       'artistic / musical / writer', 'computer / hardware / software',\n",
       "       'banking / financial / real estate', 'entertainment / media',\n",
       "       'sales / marketing / biz dev', 'other', 'medicine / health',\n",
       "       'science / tech / engineering', 'executive / management',\n",
       "       'education / academia', 'clerical / administrative',\n",
       "       'construction / craftsmanship', 'rather not say',\n",
       "       'political / government', 'law / legal services', 'unemployed',\n",
       "       'military', 'retired'], dtype=object)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['job'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([\"doesn't have kids, but might want them\", nan, \"doesn't want kids\",\n",
       "       \"doesn't have kids, but wants them\", \"doesn't have kids\",\n",
       "       'wants kids', 'has a kid', 'has kids',\n",
       "       \"doesn't have kids, and doesn't want any\",\n",
       "       \"has kids, but doesn't want more\",\n",
       "       \"has a kid, but doesn't want more\", 'has a kid, and wants more',\n",
       "       'has kids, and might want more', 'might want kids',\n",
       "       'has a kid, and might want more', 'has kids, and wants more'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['offspring'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['likes dogs and likes cats', 'has cats', 'likes cats', nan,\n",
       "       'has dogs and likes cats', 'likes dogs and has cats',\n",
       "       'likes dogs and dislikes cats', 'has dogs',\n",
       "       'has dogs and dislikes cats', 'likes dogs',\n",
       "       'has dogs and has cats', 'dislikes dogs and has cats',\n",
       "       'dislikes dogs and dislikes cats', 'dislikes cats',\n",
       "       'dislikes dogs and likes cats', 'dislikes dogs'], dtype=object)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['pets'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['agnosticism and very serious about it',\n",
       "       'agnosticism but not too serious about it', nan, 'atheism',\n",
       "       'christianity', 'christianity but not too serious about it',\n",
       "       'atheism and laughing about it',\n",
       "       'christianity and very serious about it', 'other', 'catholicism',\n",
       "       'catholicism but not too serious about it',\n",
       "       'catholicism and somewhat serious about it',\n",
       "       'agnosticism and somewhat serious about it',\n",
       "       'catholicism and laughing about it',\n",
       "       'agnosticism and laughing about it', 'agnosticism',\n",
       "       'atheism and somewhat serious about it',\n",
       "       'buddhism but not too serious about it',\n",
       "       'other but not too serious about it', 'buddhism',\n",
       "       'other and laughing about it',\n",
       "       'judaism but not too serious about it',\n",
       "       'buddhism and laughing about it',\n",
       "       'other and somewhat serious about it',\n",
       "       'other and very serious about it',\n",
       "       'hinduism but not too serious about it',\n",
       "       'atheism but not too serious about it', 'judaism',\n",
       "       'christianity and somewhat serious about it',\n",
       "       'hinduism and very serious about it',\n",
       "       'atheism and very serious about it',\n",
       "       'judaism and laughing about it',\n",
       "       'christianity and laughing about it',\n",
       "       'hinduism and laughing about it',\n",
       "       'buddhism and somewhat serious about it',\n",
       "       'islam and very serious about it', 'islam', 'hinduism',\n",
       "       'judaism and somewhat serious about it',\n",
       "       'catholicism and very serious about it',\n",
       "       'judaism and very serious about it',\n",
       "       'hinduism and somewhat serious about it',\n",
       "       'islam but not too serious about it',\n",
       "       'buddhism and very serious about it',\n",
       "       'islam and laughing about it',\n",
       "       'islam and somewhat serious about it'], dtype=object)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['religion'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['gemini', 'cancer', 'pisces but it doesn&rsquo;t matter', 'pisces',\n",
       "       'aquarius', 'taurus', 'virgo', 'sagittarius',\n",
       "       'gemini but it doesn&rsquo;t matter',\n",
       "       'cancer but it doesn&rsquo;t matter',\n",
       "       'leo but it doesn&rsquo;t matter', nan,\n",
       "       'aquarius but it doesn&rsquo;t matter',\n",
       "       'aries and it&rsquo;s fun to think about',\n",
       "       'libra but it doesn&rsquo;t matter',\n",
       "       'pisces and it&rsquo;s fun to think about', 'libra',\n",
       "       'taurus but it doesn&rsquo;t matter',\n",
       "       'sagittarius but it doesn&rsquo;t matter',\n",
       "       'scorpio and it matters a lot',\n",
       "       'gemini and it&rsquo;s fun to think about',\n",
       "       'leo and it&rsquo;s fun to think about',\n",
       "       'cancer and it&rsquo;s fun to think about',\n",
       "       'libra and it&rsquo;s fun to think about',\n",
       "       'aquarius and it&rsquo;s fun to think about',\n",
       "       'virgo but it doesn&rsquo;t matter',\n",
       "       'scorpio and it&rsquo;s fun to think about',\n",
       "       'capricorn but it doesn&rsquo;t matter', 'scorpio',\n",
       "       'capricorn and it&rsquo;s fun to think about', 'leo',\n",
       "       'aries but it doesn&rsquo;t matter', 'aries',\n",
       "       'scorpio but it doesn&rsquo;t matter',\n",
       "       'sagittarius and it&rsquo;s fun to think about',\n",
       "       'libra and it matters a lot',\n",
       "       'taurus and it&rsquo;s fun to think about',\n",
       "       'leo and it matters a lot',\n",
       "       'virgo and it&rsquo;s fun to think about',\n",
       "       'cancer and it matters a lot', 'capricorn',\n",
       "       'pisces and it matters a lot', 'aries and it matters a lot',\n",
       "       'capricorn and it matters a lot', 'aquarius and it matters a lot',\n",
       "       'sagittarius and it matters a lot', 'gemini and it matters a lot',\n",
       "       'taurus and it matters a lot', 'virgo and it matters a lot'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sign'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['sometimes', 'no', nan, 'when drinking', 'yes', 'trying to quit'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['smokes'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['english', 'english (fluently), spanish (poorly), french (poorly)',\n",
       "       'english, french, c++', ...,\n",
       "       'english (fluently), hindi (poorly), french (poorly), tamil (okay), spanish (poorly)',\n",
       "       'english (fluently), french (poorly), japanese (poorly), latin (poorly)',\n",
       "       'english (fluently), french, farsi'], dtype=object)"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['speaks'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['diet'] = df.diet.fillna('unknown')\n",
    "df['diet'] = df.diet.fillna('unknown')\n",
    "df['drinks'] = df.drinks.fillna('unknown')\n",
    "df['drugs'] = df.drugs.fillna('unknown')\n",
    "df['education'] = df.education.fillna('unknown')\n",
    "df['ethnicity'] = df.ethnicity.fillna('unknown')\n",
    "df['job'] = df.job.fillna('unknown')\n",
    "df['offspring'] = df.offspring.fillna('unknown')\n",
    "df['pets'] = df.pets.fillna('unknown')\n",
    "df['religion'] = df.religion.fillna('unknown')\n",
    "df['sign'] = df.sign.fillna('unknown')\n",
    "df['smokes'] = df.smokes.fillna('unknown')\n",
    "df['speaks'] = df.speaks.fillna('unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                                    gemini\n",
      "1                                    cancer\n",
      "2              pisces but it doesn't matter\n",
      "3                                    pisces\n",
      "4                                  aquarius\n",
      "                        ...                \n",
      "59941    cancer and it's fun to think about\n",
      "59942             leo but it doesn't matter\n",
      "59943     sagittarius but it doesn't matter\n",
      "59944       leo and it's fun to think about\n",
      "59945    gemini and it's fun to think about\n",
      "Name: sign, Length: 59946, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#another issue in the 'sign' column to change from 'doesn&rsquo;t' to 'doesn't' and from 'it&rsquo;s' to 'it's'\n",
    "df['sign'] = df['sign'].str.replace ('&rsquo;', \"'\")\n",
    "print(df['sign'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age             int64\n",
       "status         object\n",
       "sex            object\n",
       "orientation    object\n",
       "body_type      object\n",
       "diet           object\n",
       "drinks         object\n",
       "drugs          object\n",
       "education      object\n",
       "ethnicity      object\n",
       "height          int64\n",
       "income          int64\n",
       "job            object\n",
       "last_online    object\n",
       "location       object\n",
       "offspring      object\n",
       "pets           object\n",
       "religion       object\n",
       "sign           object\n",
       "smokes         object\n",
       "speaks         object\n",
       "dtype: object"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's convert the height column into integer\n",
    "df[\"height\"] = df['height'].astype('int')\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>status</th>\n",
       "      <th>sex</th>\n",
       "      <th>orientation</th>\n",
       "      <th>body_type</th>\n",
       "      <th>diet</th>\n",
       "      <th>drinks</th>\n",
       "      <th>drugs</th>\n",
       "      <th>education</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>...</th>\n",
       "      <th>income</th>\n",
       "      <th>job</th>\n",
       "      <th>last_online</th>\n",
       "      <th>location</th>\n",
       "      <th>offspring</th>\n",
       "      <th>pets</th>\n",
       "      <th>religion</th>\n",
       "      <th>sign</th>\n",
       "      <th>smokes</th>\n",
       "      <th>speaks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>59946.000000</td>\n",
       "      <td>59946</td>\n",
       "      <td>59946</td>\n",
       "      <td>59946</td>\n",
       "      <td>54650</td>\n",
       "      <td>59946</td>\n",
       "      <td>59946</td>\n",
       "      <td>59946</td>\n",
       "      <td>59946</td>\n",
       "      <td>59946</td>\n",
       "      <td>...</td>\n",
       "      <td>59946.000000</td>\n",
       "      <td>59946</td>\n",
       "      <td>59946</td>\n",
       "      <td>59946</td>\n",
       "      <td>59946</td>\n",
       "      <td>59946</td>\n",
       "      <td>59946</td>\n",
       "      <td>59946</td>\n",
       "      <td>59946</td>\n",
       "      <td>59946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>33</td>\n",
       "      <td>218</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22</td>\n",
       "      <td>30123</td>\n",
       "      <td>199</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>46</td>\n",
       "      <td>49</td>\n",
       "      <td>6</td>\n",
       "      <td>7648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>single</td>\n",
       "      <td>m</td>\n",
       "      <td>straight</td>\n",
       "      <td>average</td>\n",
       "      <td>unknown</td>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>graduated from college/university</td>\n",
       "      <td>white</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>2012-06-29-22-56</td>\n",
       "      <td>san francisco, california</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>english</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>55697</td>\n",
       "      <td>35829</td>\n",
       "      <td>51606</td>\n",
       "      <td>14652</td>\n",
       "      <td>24395</td>\n",
       "      <td>41780</td>\n",
       "      <td>37724</td>\n",
       "      <td>23959</td>\n",
       "      <td>32831</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8198</td>\n",
       "      <td>24</td>\n",
       "      <td>31064</td>\n",
       "      <td>35561</td>\n",
       "      <td>19921</td>\n",
       "      <td>20226</td>\n",
       "      <td>11056</td>\n",
       "      <td>43896</td>\n",
       "      <td>21828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>32.340290</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>20033.222534</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.452779</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>97346.192104</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>26.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>30.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>37.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>110.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 age  status    sex orientation body_type     diet    drinks  \\\n",
       "count   59946.000000   59946  59946       59946     54650    59946     59946   \n",
       "unique           NaN       5      2           3        12       19         7   \n",
       "top              NaN  single      m    straight   average  unknown  socially   \n",
       "freq             NaN   55697  35829       51606     14652    24395     41780   \n",
       "mean       32.340290     NaN    NaN         NaN       NaN      NaN       NaN   \n",
       "std         9.452779     NaN    NaN         NaN       NaN      NaN       NaN   \n",
       "min        18.000000     NaN    NaN         NaN       NaN      NaN       NaN   \n",
       "25%        26.000000     NaN    NaN         NaN       NaN      NaN       NaN   \n",
       "50%        30.000000     NaN    NaN         NaN       NaN      NaN       NaN   \n",
       "75%        37.000000     NaN    NaN         NaN       NaN      NaN       NaN   \n",
       "max       110.000000     NaN    NaN         NaN       NaN      NaN       NaN   \n",
       "\n",
       "        drugs                          education ethnicity  ...  \\\n",
       "count   59946                              59946     59946  ...   \n",
       "unique      4                                 33       218  ...   \n",
       "top     never  graduated from college/university     white  ...   \n",
       "freq    37724                              23959     32831  ...   \n",
       "mean      NaN                                NaN       NaN  ...   \n",
       "std       NaN                                NaN       NaN  ...   \n",
       "min       NaN                                NaN       NaN  ...   \n",
       "25%       NaN                                NaN       NaN  ...   \n",
       "50%       NaN                                NaN       NaN  ...   \n",
       "75%       NaN                                NaN       NaN  ...   \n",
       "max       NaN                                NaN       NaN  ...   \n",
       "\n",
       "                income      job       last_online                   location  \\\n",
       "count     59946.000000    59946             59946                      59946   \n",
       "unique             NaN       22             30123                        199   \n",
       "top                NaN  unknown  2012-06-29-22-56  san francisco, california   \n",
       "freq               NaN     8198                24                      31064   \n",
       "mean      20033.222534      NaN               NaN                        NaN   \n",
       "std       97346.192104      NaN               NaN                        NaN   \n",
       "min          -1.000000      NaN               NaN                        NaN   \n",
       "25%          -1.000000      NaN               NaN                        NaN   \n",
       "50%          -1.000000      NaN               NaN                        NaN   \n",
       "75%          -1.000000      NaN               NaN                        NaN   \n",
       "max     1000000.000000      NaN               NaN                        NaN   \n",
       "\n",
       "       offspring     pets religion     sign smokes   speaks  \n",
       "count      59946    59946    59946    59946  59946    59946  \n",
       "unique        16       16       46       49      6     7648  \n",
       "top      unknown  unknown  unknown  unknown     no  english  \n",
       "freq       35561    19921    20226    11056  43896    21828  \n",
       "mean         NaN      NaN      NaN      NaN    NaN      NaN  \n",
       "std          NaN      NaN      NaN      NaN    NaN      NaN  \n",
       "min          NaN      NaN      NaN      NaN    NaN      NaN  \n",
       "25%          NaN      NaN      NaN      NaN    NaN      NaN  \n",
       "50%          NaN      NaN      NaN      NaN    NaN      NaN  \n",
       "75%          NaN      NaN      NaN      NaN    NaN      NaN  \n",
       "max          NaN      NaN      NaN      NaN    NaN      NaN  \n",
       "\n",
       "[11 rows x 21 columns]"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#quick overview of the cleaned data\n",
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>height</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>59946.000000</td>\n",
       "      <td>59946.000000</td>\n",
       "      <td>59946.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>32.340290</td>\n",
       "      <td>68.295266</td>\n",
       "      <td>20033.222534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.452779</td>\n",
       "      <td>3.994704</td>\n",
       "      <td>97346.192104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>26.000000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>30.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>37.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>110.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                age        height          income\n",
       "count  59946.000000  59946.000000    59946.000000\n",
       "mean      32.340290     68.295266    20033.222534\n",
       "std        9.452779      3.994704    97346.192104\n",
       "min       18.000000      1.000000       -1.000000\n",
       "25%       26.000000     66.000000       -1.000000\n",
       "50%       30.000000     68.000000       -1.000000\n",
       "75%       37.000000     71.000000       -1.000000\n",
       "max      110.000000     95.000000  1000000.000000"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#quick overview just from the int columns\n",
    "df[['age','height', 'income']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploring the data, making insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f0fc8664080>"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0fc860b160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['age'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
